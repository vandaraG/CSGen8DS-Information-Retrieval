{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34e21f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the documents as a dictionary where keys are document titles and values are document content\n",
    "documents = {\n",
    "    \"Article: Pandas Basics\": \"This article covers the basics of using Pandas in Python.\",\n",
    "    \"Tutorial: Data Visualization\": \"Learn about data visualization techniques with Python libraries.\",\n",
    "    \"Case Study: Sales Analysis\": \"Analyze sales data using Python for a real-world case study.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee8fdf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Article: Pandas Basics', 'Tutorial: Data Visualization', 'Case Study: Sales Analysis']\n"
     ]
    }
   ],
   "source": [
    "# get the keys of the documents and store it in the list\n",
    "key_documents = [key for key in documents ]\n",
    "# display the list of the key documents\n",
    "print(key_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5398841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Article', 'Tutorial', 'Case Study']\n"
     ]
    }
   ],
   "source": [
    "# Extract the category of the key documents and store it \n",
    "categories = []\n",
    "for key_doc in documents:\n",
    "    category = key_doc.split(': ')[0]\n",
    "    categories.append(category)\n",
    "    \n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5353707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This article covers the basics of using Pandas in Python.', 'Learn about data visualization techniques with Python libraries.', 'Analyze sales data using Python for a real-world case study.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the content values and put them in a list\n",
    "document_content_list = list(documents.values())\n",
    "# Display the list of document content\n",
    "print(document_content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bedcd86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'about', 'Analyze', 'covers', 'Learn', 'for', 'real-world', 'article', 'with', 'a', 'case', 'basics', 'the', 'Python', 'visualization', 'study.', 'in', 'sales', 'Pandas', 'Python.', 'This', 'of', 'techniques', 'data', 'using', 'libraries.'}\n"
     ]
    }
   ],
   "source": [
    "# Gather the set of all unique terms from the list content of document and diplay the result\n",
    "#unique_terms = {term for doc_content in document_content_list for term in doc_content.split()}\n",
    "unique_terms = set()\n",
    "for doc_content in document_content_list:\n",
    "    terms = doc_content.split()\n",
    "    unique_terms.update(terms)\n",
    "print(unique_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41334ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': [0, 1, 0],\n",
       " 'Analyze': [0, 0, 1],\n",
       " 'covers': [1, 0, 0],\n",
       " 'Learn': [0, 1, 0],\n",
       " 'for': [0, 0, 1],\n",
       " 'real-world': [0, 0, 1],\n",
       " 'article': [1, 0, 0],\n",
       " 'with': [0, 1, 0],\n",
       " 'a': [1, 1, 1],\n",
       " 'case': [0, 0, 1],\n",
       " 'basics': [1, 0, 0],\n",
       " 'the': [1, 0, 0],\n",
       " 'Python': [1, 1, 1],\n",
       " 'visualization': [0, 1, 0],\n",
       " 'study.': [0, 0, 1],\n",
       " 'in': [1, 0, 1],\n",
       " 'sales': [0, 0, 1],\n",
       " 'Pandas': [1, 0, 0],\n",
       " 'Python.': [1, 0, 0],\n",
       " 'This': [1, 0, 0],\n",
       " 'of': [1, 0, 0],\n",
       " 'techniques': [0, 1, 0],\n",
       " 'data': [0, 1, 1],\n",
       " 'using': [1, 0, 1],\n",
       " 'libraries.': [0, 1, 0]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a matrix for the document by using the unique term\n",
    "doc_term_matrix = {}\n",
    "\n",
    "for term in unique_terms:\n",
    "    doc_term_matrix[term] = []\n",
    "\n",
    "    for doc_content in document_content_list:\n",
    "        if term in doc_content:\n",
    "            doc_term_matrix[term].append(1)\n",
    "        else:\n",
    "            doc_term_matrix[term].append(0)\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8a41b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n",
      "[1 1 1]\n",
      "-------\n",
      "[1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This article covers the basics of using Pandas in Python.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the numpy library if it doesn't work you need to install numpy\n",
    "import numpy as np\n",
    "\n",
    "docs_array = np.array(document_content_list, dtype='object')\n",
    "\n",
    "v1 = np.array(doc_term_matrix['the'])    \n",
    "v2 = np.array(doc_term_matrix['Python'])\n",
    "\n",
    "print(v1)\n",
    "print(v2)\n",
    "print('-------')\n",
    "\n",
    "# find the documents that have both terms from v1 and v2\n",
    "v3 = v1 & v2\n",
    "\n",
    "print(v3)\n",
    "\n",
    "# display the content document from the result\n",
    "...\n",
    "[doc for doc in v3 * docs_array if doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11484192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n",
      "[1 1 1]\n",
      "-------\n",
      "[1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This article covers the basics of using Pandas in Python.',\n",
       " 'Learn about data visualization techniques with Python libraries.',\n",
       " 'Analyze sales data using Python for a real-world case study.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the document for those have at least one word\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "docs_array = np.array(document_content_list, dtype='object')\n",
    "\n",
    "v1 = np.array(doc_term_matrix['the'])    \n",
    "v2 = np.array(doc_term_matrix['Python'])\n",
    "\n",
    "print(v1)\n",
    "print(v2)\n",
    "print('-------')\n",
    "\n",
    "# find the documents that have both terms from v1 and v2\n",
    "v3 = v1 | v2\n",
    "\n",
    "print(v3)\n",
    "\n",
    "# display the content document from the result\n",
    "...\n",
    "[doc for doc in v3 * docs_array if doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "939f3763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------------------------------------------------+\n",
      "|    | Documents   | Contents                                                     |\n",
      "+====+=============+==============================================================+\n",
      "|  0 | Document 1  | This is the first document. It contains some words.          |\n",
      "+----+-------------+--------------------------------------------------------------+\n",
      "|  1 | Document 2  | The second document is a bit longer and has different words. |\n",
      "+----+-------------+--------------------------------------------------------------+\n",
      "|  2 | Document 3  | The third document is short. Short documents can be concise. |\n",
      "+----+-------------+--------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def print_csv_as_table(csv_file_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file_path, header=None, names=['Documents', 'Contents'])\n",
    "\n",
    "    # Set the maximum column width to a large value to prevent truncation\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    # Set the column headers to be left-aligned\n",
    "    pd.set_option('display.colheader_justify', 'center')\n",
    "\n",
    "    # Print the DataFrame as a table\n",
    "    table = tabulate(df, headers='keys', tablefmt='grid')\n",
    "    print(table)\n",
    "\n",
    "# Example usage:\n",
    "csv_file_path = '/Users/vandaragnep/Downloads/tdoc.csv'\n",
    "print_csv_as_table(csv_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ddb7a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "unique_terms = set()\n",
    "for doc_content in document_content_list:\n",
    "    terms = doc_content.split()\n",
    "    unique_terms.update(terms)\n",
    "with open('unique_terms.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(unique_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e09eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f417d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
